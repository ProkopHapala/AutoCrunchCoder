
512
1024
2048
4096
8192
16384
32768
65536


## DeepSeek-Coder-2-16B

lmstudio-community/DeepSeek-Coder-V2-Lite-Instruct-GGUF/DeepSeek-Coder-V2-Lite-Instruct-Q4_K_M.gguf

#### Test 1

Constext length : 8192
Batch Size      : 512
Flash Attention : No

nvidia-smi
alone: 12496 MiB
total: 14248 MiB

#### Test 2

Constext length : 16384
Batch Size      : 1024
Flash Attention : No

nvidia-smi
alone: 14928 MiB
total: 16572 MiB

#### Test 3

Constext length : 32768
Batch Size      : 512
Flash Attention : No

nvidia-smi
alone: 21431 MiB
total: 19792 MiB


## Codestral-22B

lmstudio-community/DeepSeek-Coder-V2-Lite-Instruct-GGUF/DeepSeek-Coder-V2-Lite-Instruct-Q4_K_M.gguf

#### Test 1

Constext length : 4096
Batch Size      : 512
Flash Attention : yes

nvidia-smi
alone: 14224 MiB
total: 15849 MiB

#### Test 2

Constext length : 16384
Batch Size      : 512
Flash Attention : yes

nvidia-smi
alone: 18088 MiB
total: 19705 MiB


#### Test 2

Constext length : 24576
Batch Size      : 512
Flash Attention : yes

nvidia-smi
alone: 20664 MiB
total: 22337 MiB


## Llama-3.1-8B

lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf


#### Test 1

Constext length : 32768
Batch Size      : 512
Flash Attention : yes

nvidia-smi
alone: 7098 MiB
total: 8803 MiB

#### Test 1

Constext length : 32768
Batch Size      : 512
Flash Attention : No

nvidia-smi
alone: 10916 MiB
total: 12577 MiB

#### Test 1


Constext length : 65536
Batch Size      : 512
Flash Attention : yes

nvidia-smi
alone: 18937 MiB 
total: 17124 MiB


